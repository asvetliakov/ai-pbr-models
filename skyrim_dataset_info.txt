----------------------- Segformer: With separate ceramic class ----------------------

Pixels per class (All):
ceramic: 144334882 pixels (2.0541%)
fabric: 733744755 pixels (10.4422%)
ground: 661862150 pixels (9.4192%)
leather: 520160536 pixels (7.4026%)
metal: 1244041442 pixels (17.7044%)
stone: 2546824293 pixels (36.2448%)
wood: 1175756876 pixels (16.7326%)

Samples per class with >1% ratio:
ceramic: 133 samples
fabric: 582 samples
ground: 276 samples
leather: 617 samples
metal: 1041 samples
stone: 1133 samples
wood: 662 samples

Validation set size: 319
Training set size: 2877

Class weights for training dataset:
{'ceramic': 2.110427016563956, 'fabric': 0.9084989760508438, 'ground': 0.9883458124089929, 'leather': 1.0895438981748855, 'metal': 0.6995011622473395, 'stone': 0.4881979607448465, 'wood': 0.7154851738091358}
2877.000148534775
Min/Max weight: 0.7560208439826965 2.5200703144073486
Oversample factor for heaviest image: 3.3333344370926192

Ceramic heterogeneous ( 1/1.5/3% <= freq < 30% ) crops found: 256x256: 1209, 512x512: 484, 768x768: 454

----------------------- Segformer: Ceramic has been merged into stone ----------------------

Pixels per class (All):
fabric: 735573587 pixels (10.4698%)
ground: 661862150 pixels (9.4207%)
leather: 525012980 pixels (7.4728%)
metal: 1247248006 pixels (17.7528%)
stone: 2684390338 pixels (38.2084%)
wood: 1171562572 pixels (16.6755%)

Samples per class with >40% ratio:
fabric: 352 samples
ground: 268 samples
leather: 343 samples
metal: 636 samples
stone: 1146 samples
wood: 543 samples

Validation set size: 319
Training set size: 2875

Class weights for training dataset:
{'fabric': 1.1340966971713928, 'ground': 1.1902877105015872, 'leather': 1.35098788414536, 'metal': 0.8497113921330618, 'stone': 0.5827968731001469, 'wood': 0.892119442948451}
2874.9999694228172
Min/Max weight: 0.6591277122497559 2.1970930099487305
Oversample factor for heaviest image: 3.333334297915562

----------------------- Segformer: Best Model Confusion Matrix (S3 Epoch 2) ----------------------

Note: ground -> stone confusion can be beneficial

True\Pred       fabric    ground   leather     metal     stone      wood
fabric           89.4%      0.0%      8.4%      0.3%      0.6%      1.2%
ground            0.0%     85.1%      0.0%      0.0%     12.1%      2.8%
leather           2.8%      0.0%     92.3%      3.8%      0.8%      0.2%
metal             0.6%      0.0%      5.7%     89.9%      0.9%      3.0%
stone             0.0%      0.6%      1.8%      0.4%     97.2%      0.0%
wood              0.1%      0.0%      0.8%      3.4%      2.9%     92.9%

Alternative S4 epoch 3
True\Pred       fabric    ground   leather     metal     stone      wood
fabric           90.0%      0.0%      8.1%      0.2%      0.6%      1.1%
ground            0.0%     91.6%      0.0%      0.0%      5.6%      2.8%
leather           3.0%      0.0%     92.6%      3.6%      0.4%      0.3%
metal             1.0%      0.0%      6.8%     88.3%      0.6%      3.3%
stone             0.0%      3.6%      1.9%      0.6%     93.9%      0.1%
wood              0.2%      0.0%      0.8%      3.3%      2.5%     93.2%


----------------------- Unet-Albedo dataset info ----------------------
Pixels per class (All):
fabric: 538478754 pixels (8.8969%)
ground: 661862150 pixels (10.9354%)
leather: 294813723 pixels (4.8710%)
metal: 821458456 pixels (13.5723%)
stone: 2628749203 pixels (43.4328%)
wood: 1107088084 pixels (18.2916%)

Samples per class with >40% ratio:
fabric: 260 samples
ground: 268 samples
leather: 195 samples
metal: 408 samples
stone: 1116 samples
wood: 526 samples

Validation set size: 271
Training set size: 2443

Class weights for training dataset:
{'fabric': 1.135688955433771, 'ground': 1.0494288681455244, 'leather': 1.5682429415555577, 'metal': 0.9314057068409406, 'stone': 0.5173477516737343, 'wood': 0.7978857763504716}
2443.000176668167
Min/Max weight: 0.7232559323310852 2.410853862762451
Oversample factor for heaviest image: 3.3333343772130077


----------------------- Unet-Parallax dataset info ----------------------
Pixels per class (All):
fabric: 459955961 pixels (8.1120%)
ground: 661278506 pixels (11.6626%)
leather: 208432475 pixels (3.6760%)
metal: 759094069 pixels (13.3878%)
stone: 2514113728 pixels (44.3401%)
wood: 1067188674 pixels (18.8215%)

Samples per class with >40% ratio:
fabric: 208 samples
ground: 267 samples
leather: 157 samples
metal: 373 samples
stone: 1067 samples
wood: 490 samples

Validation set size: 250
Training set size: 2256

Class weights for training dataset:
{'fabric': 1.144883274956107, 'ground': 0.9769040783800758, 'leather': 1.760962304703703, 'metal': 0.8892416868562821, 'stone': 0.4859172365844548, 'wood': 0.7420914185193779}
2256.000212430954
Min/Max weight: 0.757355809211731 2.5245201587677
Oversample factor for heaviest image: 3.33333438267974

----------------------- Unet-Maps (except parallax) dataset info ----------------------
Pixels per class (All):
fabric: 949110070 pixels (11.8552%)
ground: 668381776 pixels (8.3487%)
leather: 727010977 pixels (9.0810%)
metal: 1684118953 pixels (21.0361%)
stone: 2713622293 pixels (33.8954%)
wood: 1263617256 pixels (15.7837%)

Samples per class with >40% ratio:
fabric: 383 samples
ground: 269 samples
leather: 364 samples
metal: 752 samples
stone: 1159 samples
wood: 558 samples

Validation set size: 336
Training set size: 3026

Class weights for training dataset:
{'fabric': 1.0838312780734976, 'ground': 1.3024449437117986, 'leather': 1.247075788676818, 'metal': 0.8092630788514052, 'stone': 0.6308490467882556, 'wood': 0.9265358638982252}
3026.000090241432
Min/Max weight: 0.655806303024292 2.1860218048095703
Oversample factor for heaviest image: 3.3333345451676712