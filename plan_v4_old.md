# üåÑ End‚Äëto‚ÄëEnd PBR Conversion Plan ‚Äî _No‚ÄëViT, Multi‚ÄëMask SegFormer_

_(Version¬†4.5‚ÄÇ¬∑‚ÄÇ18‚ÄØJun‚ÄØ2025)_

---

## MatSynth category hygiene

| Category                                                 | Action & Reason                                                                          |
| -------------------------------------------------------- | ---------------------------------------------------------------------------------------- |
| **plastic**                                              | **Drop** ‚Äì anachronistic.                                                                |
| **concrete**                                             | **Merge ‚Üí stone** ‚Äì roughness/height similar; makes SegFormer‚Äôs job easier.              |
| **marble**                                               | If Skyrim mod pack has no marble, **merge into stone**; else keep (rare indoor pillars). |
| **plaster**                                              | **Drop**                                                                                 |
| **terracotta**                                           | Very rare ‚Üí **drop**.                                                                    |
| **misc**                                                 | Contains heterogeneous, often modern designs ‚Üí **drop**.                                 |
| **ceramic, fabric, ground, leather, metal, wood, stone** | **Keep**. Add `fur` if you have ‚â•‚ÄØ100 samples.                                           |

---

## ü™ú¬†Phase Ladder ‚Äî with goals, metrics & advice

| Phase  | Goal (one‚Äëliner)                                      | Dataset Mix    | Trainable Modules                        | Crop     | Augment (new‚ÄØ‚Üí‚ÄØold)                                |
| ------ | ----------------------------------------------------- | -------------- | ---------------------------------------- | -------- | -------------------------------------------------- |
| **A0** | Smoke‚Äëtest pipeline; get first masks & maps.          | 100‚ÄØ%‚ÄØMatSynth | SegFormer, UNet‚ÄëAlbedo, UNet‚ÄëMaps (all)  | 256‚ÄØpx   | none                                               |
| **A**  | Learn clean PBR priors on single‚Äëmaterial textures.   | 100‚ÄØ% MatSynth | same                                     | 256‚ÄØpx   | flips ¬∑ rot ¬∑ jitter ¬∑ composites (SegFormer only) |
| **B**  | Introduce Skyrim; adapt heads with FiLM conditioning. | 75‚ÄØ%/25‚ÄØ%      | SegFormer heads+LoRA; UNet decoder heads | 256‚Üí512  | Photometric (Skyrim) ¬∑ composites (All)            |
| **C**  | Deep adaptation; unfreeze upper encoder layers.       | 50‚ÄØ%/50‚ÄØ%      | top‚ÄØ¬Ω encoders + heads                   | 512‚Üí768  | same, lower composite %                            |
| **C‚Ä≤** | Stabilise BN/LN stats for 2‚ÄØK jump.                   | 50‚ÄØ%/50‚ÄØ%      | BN/LN only                               | 1‚ÄØK      | none                                               |
| **D**  | High‚Äëres detail for each map at 2‚ÄØK.                  | 100‚ÄØ% Skyrim   | per‚Äëmap head job                         | full 2‚ÄØK | Photometric¬†√ó‚ÄØ0.5                                  |

Below, each phase is _self‚Äëcontained_.

---

### 1Ô∏è‚É£¬†Phase‚ÄØA0 ‚Äî _‚ÄúDoes it run?‚Äù_

| Item                       | Setting                                                                                                  |
| -------------------------- | -------------------------------------------------------------------------------------------------------- |
| **Description**            | 10‚Äëepoch sprint: ensure dataloader, losses, GPU work.                                                    |
| **Optimizer**              | `AdamW(lr=1e‚Äë4, wd=1e‚Äë2)`                                                                                |
| **Scheduler**              | `CosineAnnealingLR(T_max=10)`                                                                            |
| **Augment**                | none                                                                                                     |
| **SegFormer ground‚Äëtruth** | _whole image mask_ = class id (easy single‚Äëmaterial)                                                     |
| **Losses**                 | SegFormer‚ÄØ‚Üí‚ÄØ`CrossEntropy2d` (mask¬†= class id) <br>UNet‚ÄëAlbedo‚ÄØ‚Üí‚ÄØ`maksed L1` <br>UNet‚ÄëMaps‚ÄØ‚Üí‚ÄØ`masked L1` |
| **Log / Watch**            | `mat_val_loss` (expect sharp ‚Üì), `seg_iou` (‚â•‚ÄØ0.55), `u_alb_L1`                                          |
| **Recommendations**        | If any loss is `nan`, fix data normalisation before advancing.                                           |

---

### 2Ô∏è‚É£¬†Phase‚ÄØA ‚Äî _Clean MatSynth Learning_

| Item                   | Setting                                                                                                                            |
| ---------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |
| **Epochs**             | 35                                                                                                                                 |
| **Description**        | 35‚ÄØepochs to build strong physics priors. Composites automatically create multi‚Äëmaterial masks for SegFormer.                      |
| **Optimizer**          | `AdamW(lr 5e‚Äë5‚Üí1e‚Äë5)`                                                                                                              |
| **Scheduler**          | `OneCycleLR(max_lr=5e‚Äë5, pct_start=0.15)`                                                                                          |
| **Augment**            | flips, 90¬∞ rot, colour‚Äëjitter; **composites (SegFormer only)**<br>¬†¬†‚Ä¢ 2‚Äëcrop‚ÄØ30‚ÄØ%<br>¬†¬†‚Ä¢ 4‚Äëcrop‚ÄØ15‚ÄØ%                               |
| **SegFormer GT**       | composites know patch coordinates ‚áí auto mask                                                                                      |
| **Curriculum crop**    | fixed 256‚ÄØpx                                                                                                                       |
| **Losses**             | same as A0 plus, `UNet-albedo`: `masked L1 + 0.1 * SSIM + 0.05 * LPIPS` (both training & validation), `Unet-maps`: see table below |
| **Additional Metrics** | LPIPS on albedo; IoU on SegFormer per‚Äëclass                                                                                        |
| **Gate**               | proceed when losses plateau <‚ÄØ4‚ÄØepochs                                                                                             |
| **Advice**             | Over‚Äëfitting shows as LPIPS ‚Üë while L1 ‚Üì. Stop early if that happens.                                                              |

### Unet-maps loss table

| Map           | Range        | Loss terms                                                                          |
| ------------- | ------------ | ----------------------------------------------------------------------------------- |
| **Roughness** | 0-1          | `masked_L1` + **0.05 √ó SSIM**                                                       |
| **Metallic**  | 0-1          | Full-image BCE (From Metallic mask GT) + pos_weight = #neg / #pos. No explicit mask |
| **AO**        | 0-1          | `masked_L1`                                                                         |
| **Height**    | unrestricted | `masked_L1` + **0.01 √ó Grad-penalty** (encourage smoothness)                        |

_Validation loss fro UNet-maps_
Same losses but WITHOUT gradient penalty (TV) to save time

_Masked L1 examles:_

| Model-head                               | What is **foreground** (`material_mask==1`)                                                                                                                                                                        | When to apply                                                 |
| ---------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------- |
| **UNet-Albedo**                          | All _valid_ pixels (because the whole albedo image is relevant) ‚Üí just pass `material_mask = torch.ones_like(pred[:, :1])`. Effectively your `masked_l1` simplifies to plain L1 but keeps the same call-signature. | Phases A ‚Üí D                                                  |
| **UNet-Maps** (rough, metal, AO, height) | Pixels **belonging to the map‚Äôs material**. Example for metallic head:<br>`material_mask = (segformer_pred == metal_idx)` (upsampled to H√óW).                                                                      | Phases B ‚Üí D (when SegFormer is good enough to provide masks) |

_Metal mask_ per phases
| phase | supervision available | suggested loss |
| --------------------------------------------------- | ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **A** (MatSynth 100 %) | _perfect_ GT metallic maps | **Full-image BCE** + `pos_weight = #neg / #pos`. No explicit mask. |
| **B / C** (MatSynth + Skyrim, masks from SegFormer) | SegFormer masks have some error | Two equally good options: <br>**(i)** Keep full-image BCE + `pos_weight`. The BCEloss is hardy to a few wrong pixels.<br>**(ii)** Go back to masked BCE but use a small background weight, e.g. `weight = 0.2 + 0.8*mask_metal` so negatives still matter a bit. |
| **D** (2 K, masks fixed) | SegFormer very stable | Either strategy works ‚Äì most people stay with whatever they used in C. |

```python
# Albedo
loss_alb = masked_l1(alb_pred, alb_gt,
                     material_mask = torch.ones_like(alb_pred[:, :1]))

# Metallic map (example)
metal_mask = (seg_pred == metal_idx).unsqueeze(1)          # (B,1,H,W) bool
loss_met = masked_l1(metal_pred, metal_gt, metal_mask)

```

_Loss examples:_

```python
# unet-albedo
l1      = masked_l1(pred_alb, gt_alb, torch.ones_like(gt_alb[:, :1]))
ssim    = 1 - pytorch_msssim.ssim(pred_alb, gt_alb, data_range=1.0)
lpips_v = lpips_fn(pred_alb, gt_alb)          # e.g. LPIPS-Alex, avg over batch
loss_alb = l1 + 0.10*ssim + 0.05*lpips_v

# Unet-maps
# Roughness (foreground = any non-empty mask)
rough_mask = (gt_metal < 0.5) | (gt_metal >= 0.5)  # simply ones
loss_rough = masked_l1(pred_rough, gt_rough, rough_mask) \
           + 0.05 * (1 - ssim(pred_rough, gt_rough))

# Metallic (only evaluate where material truly metal)
# loss_metal = F.binary_cross_entropy(pred_metal, gt_metal,
#                                     weight = metal_mask.float())
# count positive / negative pixels in this mini-batch
pos = metallic_gt.sum()
neg = metallic_gt.numel() - pos
pos_weight = neg.float() / pos.clamp(min=1.)   # scalar

loss_metal = F.binary_cross_entropy_with_logits(
                 metallic_pred, metallic_gt,
                 pos_weight = pos_weight)   # reduction='mean'


# AO
loss_ao = masked_l1(pred_ao, gt_ao, torch.ones_like(gt_ao))

# Height (add TV penalty)
tv = torch.mean(torch.abs(pred_h[:, :, :, :-1] - pred_h[:, :, :, 1:])) \
   + torch.mean(torch.abs(pred_h[:, :, :-1, :] - pred_h[:, :, 1:, :]))
loss_h = masked_l1(pred_h, gt_h, torch.ones_like(gt_h)) + 0.01*tv

loss_maps = (loss_rough + loss_metal + loss_ao + loss_h) / 4
```

_Summary_:
| Stage | UNet-Albedo loss | UNet-Maps loss |
| ---------------- | ---------------------------- | ---------------------------------------------- |
| **A0 smoke** | only `masked_L1` (quick) | skip |
| **A (MatSynth)** | `L1 + 0.1¬∑SSIM + 0.05¬∑LPIPS` | 4-map average as above (mask from GT category) |
| **B / C (mix)** | same as A | same, but masks now from **SegFormer preds** |
| **D (2 K)** | _freeze_ ALB; no loss | per-head training, use respective map-loss |

## Where to use GT albedo vs. predicted albedo

| Phase                        | Maps-net **input**                                                          | `detach()`?                                                                                         | Why this is the safest default                                                                                                                                                                                                                       |
| ---------------------------- | --------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **A0**‚ÄÉSmoke-test            | **GT albedo** only                                                          | _irrelevant_ ‚Äì no grad path through constants                                                       | Keep the pipeline trivial while you-re still shaking out loaders & losses.                                                                                                                                                                           |
| **A**‚ÄÉClean MatSynth (35 ep) | **Warm-up (‚âà first 5-10 ep)**: GT albedo ‚Üí<br>**Main run**: **pred albedo** | **Yes** (keep heads independent)                                                                    | GT warm-up lets Maps net learn the pure mapping.<br>Once Albedo stabilises you expose Maps to realistic noise, but you _don‚Äôt_ want its loss to drag Albedo away from its own objective.                                                             |
| **B**‚ÄÉHead-only domain-adapt | **pred albedo**                                                             | **Yes**                                                                                             | You‚Äôre freezing most backbones; the Maps loss shouldn‚Äôt be trying to move Albedo‚Äôs frozen layers.                                                                                                                                                    |
| **C**‚ÄÉPartial unfreeze       | **pred albedo**                                                             | **Two-step**<br>‚Ä¢ first 50 % of epochs: **Yes**<br>‚Ä¢ final 3-4 ep: **No** (joint finetune, tiny lr) | Early in C you‚Äôre still chasing stability after the unfreeze ‚Äì keep heads decoupled. Once losses flatten, letting the Maps gradients polish Albedo can give a small boost to global coherence. Use a very low LR (e.g. √ó0.25) during the joint pass. |
| **C‚Ä≤**‚ÄÉBN/LN warm-up         | **pred albedo**                                                             | **Yes** (or leave Albedo frozen)                                                                    | Goal is just stats refresh; keep optimisation local.                                                                                                                                                                                                 |
| **D**‚ÄÉ2 K per-map heads      | **pred albedo**                                                             | _irrelevant_ ‚Äì Albedo backbone/head is frozen                                                       | At this point Albedo is immutable; detach for clarity but it won‚Äôt matter.                                                                                                                                                                           |

---

### 4Ô∏è‚É£¬†Phase‚ÄØB ‚Äî _Head‚ÄëLevel Domain Adapt_

| Item                      | Setting                                                                              |
| ------------------------- | ------------------------------------------------------------------------------------ |
| **Dataset mix**           | 75‚ÄØ% MatSynth ¬∑ 25‚ÄØ% Skyrim                                                          |
| **Trainable**             | SegFormer heads¬†+¬†LoRA; UNet decoder heads; enable **FiLM conditioning**             |
| **Epochs**                | 10                                                                                   |
| **Curriculum crop**       | 256‚ÄØpx ‚Üí¬†512‚ÄØpx (linear each epoch)                                                  |
| **Augment (Skyrim only)** | `SkyrimPhotometric(p=0.6)`                                                           |
| **Pseudo‚Äëlabel trick**    | For Skyrim pixels where SegFormer `softmax‚ÄØ>‚ÄØ0.8`, include them in CE loss.          |
| **Optimizer /‚ÄØSched**     | `AdamW(lr 1e‚Äë5)`                                                                     |
| **Scheduler**             | `StepLR(6, Œ≥=0.5)`                                                                   |
| **Losses**                | SegFormer: CE on MatSynth + **masked CE** on Skyrim;<br>UNet‚ÄëAlbedo/Maps: same as A. |
| **Metrics**               | `sky_val_loss`, `mat_val_loss`, `seg_iou_sky`, `seg_iou_mat`                         |
| **Gate rule**             | last‚Äë3¬†epochs: ¬†`sky_val_loss ‚â§ 0.95*prev` & `mat_val_loss ‚â§ 1.10*prev`              |
| **Personal advice**       | Watch SegFormer IoU on _metal_ channel; should climb from ~0.30 ‚Üí¬†0.55+.             |

---

### 5Ô∏è‚É£¬†Phase‚ÄØC ‚Äî _Partial Unfreeze Deep Adapt_

| Item                  | Setting                                                                                       |
| --------------------- | --------------------------------------------------------------------------------------------- |
| **Goal**              | Let upper encoders specialise to Skyrim while retaining MatSynth priors.                      |
| **Dataset mix**       | 50‚ÄØ% /‚ÄØ50‚ÄØ%                                                                                   |
| **Trainable**         | top‚ÄØ50‚ÄØ% encoders¬†+ heads; LoRA still active. keep FiLM                                       |
| **Epochs**            | 10                                                                                            |
| **Optimizer /‚ÄØSched** | `AdamW(lr 5e‚Äë6, Œ≤‚ÇÇ=0.9995)`                                                                   |
| **Scheduler**         | `CosineAnnealingLR(T_max=12)`                                                                 |
| **Crop schedule**     | 512‚ÄØpx ‚Üí¬†768‚ÄØpx                                                                               |
| **Augment**           | composites rate ‚Üì (2‚Äëcrop 20‚ÄØ%, 4‚Äëcrop 10‚ÄØ%); Photometric unchanged                           |
| **Metrics**           | same + per‚Äëclass SegFormer IoU; monitor catastrophic forgetting (stone/wood should not dive). |
| **Advice**            | If MatSynth IoU falls >10‚ÄØ% from Phase‚ÄØA, reduce unfreeze depth to 25‚ÄØ%.                      |

---

### 6Ô∏è‚É£¬†Phase‚ÄØC‚Ä≤ ‚Äî _BN/LN Stats Warm‚Äëup_

| Item          | Setting                                                          |
| ------------- | ---------------------------------------------------------------- |
| **Purpose**   | Correct running mean/var for up‚Äëcoming 2‚ÄØK strides.              |
| **Trainable** | **only** BN/LN affine params.                                    |
| **Epochs**    | 2                                                                |
| **Optimizer** | `AdamW(lr 3e‚Äë6)`                                                 |
| **Scheduler** | cosine warm‚Äërestart                                              |
| **Crop**      | full 1‚ÄØK                                                         |
| **Metrics**   | ensure val losses don‚Äôt spike; if they do, increase to 4‚ÄØepochs. |
| **Advice**    | Disable dropout during this phase.                               |

---

### 7Ô∏è‚É£¬†Phase‚ÄØD ‚Äî _2‚ÄØK Per‚ÄëMap High‚ÄëDetail_

| Common settings | value                            |
| --------------- | -------------------------------- |
| **Dataset**     | 100‚ÄØ% Skyrim @‚ÄØ2048¬≤             |
| **Photometric** | SkyrimPhotometric strength √ó‚ÄØ0.5 |
| **Freeze**      | **all backbones**                |
| **Early‚Äëstop**  | patience‚ÄØ3‚ÄØepochs/head           |

| Job (script)                                | Trainable Layers             | Epochs | Optimizer                  | Scheduler       | Metrics to watch       |
| ------------------------------------------- | ---------------------------- | ------ | -------------------------- | --------------- | ---------------------- |
| `seg_D` (all masks)                         | SegFormer decoder head       | 6      | `AdamW(lr 1e‚Äë6, wd 1e‚Äë2)`  | `StepLR(4,0.5)` | IoU_metal ‚Üë, IoU_avg ‚Üë |
| `u_alb_D`                                   | final upsample / output conv | 8      | `Adam(lr 1e‚Äë6, Œ≤‚ÇÇ=0.9995)` | `ExpLR(Œ≥=0.9)`  | LPIPS_sky ‚Üì (<‚ÄØ0.18)   |
| `u_maps_D_<map>` (rough, metal, ao, height) | map‚Äëspecific output conv     | 5‚Äë8    | same                       | same            | masked*L1*<map> ‚Üì      |

> **Recommendation:** run `seg_D` first so the freshest logits feed UNet‚ÄëMaps jobs.

---

## ü§ñ¬†Personal Recommendations

-   GPU memory ‚Äì keep per‚Äëmap Phase‚ÄØD jobs under 12‚ÄØGB by --channels_last and torch.compile (PyTorch‚ÄØ2.1).
-   Synthetic diffuse ‚Äì after Phase‚ÄØB you may lower its sampling weight to 0.3 to avoid over‚Äëregularising shadows.
-   Fur class (optional) ‚Äì if added, monitor IoU_fur; it‚Äôs usually the hardest.
-   SegFormer depth ‚Äì tiny B1 model is enough (‚âà‚ÄØ25‚ÄØM params). Large models slow Phase‚ÄØD.

---

## General training tips

1. Training order per phase: SegFormer, UNet-Albedo, UNet-Maps

-   UNet-Maps uses SegFormer best checkpoint from this Phase

2. In Phase D freeze everything and leave only specific head (roughness, metallic, etc...) then train in separate runs per specific head

-   Each head continue from the best checkpoint from previous head, e.g. train roughness head first -> metallic loads results from roughness train and continue with metallic head, etc

## Sampling

| Tactic                                      | What you do                                                                                              | Pros                                                | Cons                                                                                  | When to use                                                                                  |
| ------------------------------------------- | -------------------------------------------------------------------------------------------------------- | --------------------------------------------------- | ------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- |
| **1. Per-class loss weights** _(easy)_      | Multiply the **SegFormer CE loss** and **masked-L1 losses** by `1 / ‚àöfreq(class)` (or focal-like power). | One-liner; no change to sampling.                   | Large classes still dominate the **features learned** in early epochs.                | Always do this as a baseline.                                                                |
| **2. Balanced sampler**                     | Use `torch.utils.data.WeightedRandomSampler` so every mini-batch has \~uniform class distribution.       | Equal gradient signal per class; simple to plug in. | Over-sampling a rare class shows the _same_ images more often ‚Üí slight over-fit risk. | When minority class < ¬Ω of majority (e.g. ground 260 vs metal 800).                          |
| **3. Synthetic augmentation of minorities** | Apply extra augmentations **only** to minority textures (e.g. hue shift, cut-mix two ground variants).   | Extra diversity avoids over-fit in 2.               | More code; careful not to change semantics (e.g. don‚Äôt tint ground purple).           | If you have < 200 unique textures in a class.                                                |
| **4. Class merging or dropping**            | Fold extremely small or irrelevant classes into a parent (you already merged concrete‚Üístone).            | Simplifies head; removes imbalance completely.      | Loses fine category detail.                                                           | Only when class < 50 images **and** not visually distinct (you‚Äôve done most merges already). |

### Minimal pytorch code for 1 + 2

```python
# dataset_build.py
import json, torch
from torch.utils.data import DataLoader, WeightedRandomSampler

# ---------- 1) compute class frequencies ----------
json_labels = json.load(open("splits/MatSynth_train.json"))
all_labels  = [item["class_id"] for item in json_labels]  # list[int]

num_classes = len(set(all_labels))
cls_counts  = torch.bincount(torch.tensor(all_labels), minlength=num_classes)
freq        = cls_counts.float() / cls_counts.sum()

# ---------- loss weights (tactic 1) ----------
loss_weights = 1.0 / torch.sqrt(freq + 1e-6)
seg_loss_fn  = torch.nn.CrossEntropyLoss(weight=loss_weights, ignore_index=255)

# ---------- sampler weights (tactic 2) ----------
inv_freq   = 1.0 / (cls_counts[all_labels].float())  # per-sample weight
sampler    = WeightedRandomSampler(inv_freq, num_samples=len(inv_freq), replacement=True)

train_loader = DataLoader(dataset, batch_size=4, sampler=sampler, num_workers=4)
```

_Explanation_

-   weight ‚àù 1/‚àöfreq for loss keeps gradients stable without exploding rare classes.
-   Weighted sampler picks minority images more often, yielding roughly balanced batches.

| Phase        | Use sampler?                             | Use loss weights?                                                         |
| ------------ | ---------------------------------------- | ------------------------------------------------------------------------- |
| A0           | **No** (keep pipeline minimal)           | **Yes**                                                                   |
| A, A-Alb-Syn | Yes                                      | Yes                                                                       |
| B, C, C‚Ä≤     | Yes _(on combined MatSynth+Skyrim list)_ | Yes                                                                       |
| D            | **No sampler** (100 % Skyrim)            | Keep loss weights ‚Äì within Skyrim, fur vs ground may still be imbalanced. |

**Tips & gotchas**

-   Always use class-weighted losses.
-   Add a simple WeightedRandomSampler whenever a class is ‚â§ 50 % of the largest class (ground 260 vs wood 800 qualifies).
-   Log per-class IoU in train_logs. If ground still lags (< 0.4 when others are 0.6+), bump sampler weights by 1/freq (instead of 1/‚àöfreq).
-   Freeze sampler after Phase B if the network starts to over-fit (val loss diverges while train loss falls).
-   Synthetic augment for ground ‚Äì easiest win: add small random gamma (¬±10 %) or overlay 5 % Perlin-noise dirt masks; do not hue-shift stones or tree bark (looks wrong).
-   Checkpoint names ‚Äì append bal tag, e.g. seg_B_bal_best.pth, to remind you that a balanced sampler was used.
-   Keep Phase D simple‚Äîby then you have only Skyrim, so imbalance is smaller.

## Augment table

---

Phase A0 : none
Phase A : flip, rot, jitter (Mat), composites (Mat)
Phase B : flip, rot, jitter (Mat), composites (Mat), Photometric (Sky)
Phase C : same as B but composites 20‚ÄØ/‚ÄØ10‚ÄØ%
Phase D : none (+Photometric 0.5√ó Sky)

| Augmentation                               | Why you keep it                                                                                                     | Which phases                                          | Domain                                                                                           |
| ------------------------------------------ | ------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------- | ------------------------------------------------------------------------------------------------ |
| **Horizontal/vertical flip**               | Doubles effective dataset size; harmless for texture orientation.                                                   | A,‚ÄØB,‚ÄØC                                               | MatSynth‚ÄØ+‚ÄØSkyrim                                                                                |
| **90‚ÄØ¬∞ rotations**                         | Adds rotational variety; needed because many Skyrim textures tile in both axes.                                     | A,‚ÄØB,‚ÄØC                                               | MatSynth‚ÄØ+‚ÄØSkyrim                                                                                |
| **Colour‚Äëjitter** _(¬±5‚ÄØ% hue/sat)_         | Prevents the network from over‚Äëfitting to a single white‚Äëbalance in MatSynth.                                       | A,‚ÄØB,‚ÄØC                                               | **MatSynth only** (Skyrim already gets Photometric).                                             |
| **Composite crops** (2‚Äë & 4‚Äëpatch mosaics) | **Critical**: they are your _only_ source of _pixel‚Äëaccurate multi‚Äëmaterial masks_ for SegFormer during Phases‚ÄØA‚ÄìC. | A (30‚ÄØ% /‚ÄØ15‚ÄØ%)<br>B (30‚ÄØ% /‚ÄØ15‚ÄØ%)<br>C (20‚ÄØ% /‚ÄØ10‚ÄØ%) | MatSynth only. For composite crops take random samples from whole dataset not just current batch |

### üñºÔ∏è How cropping works vs. composite mosaics

| Term                   | What you actually do                                                                                                                                                                   | Where it happens                                                                 |
| ---------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- |
| **Random crop (N px)** | Take a **square patch of side =N pixels** from the input texture, then **_resize it back_** to the model‚Äôs fixed input size (1 K for Phases A‚ÄìC, or 2 K in Phase D).                   | Every phase that lists a crop size (256, 512, 768).                              |
| **Composite mosaic**   | Tile **2 or 4 independent _already-cropped_ patches** side-by-side to fill a 1 K canvas. Each sub-patch keeps its own ground-truth mask ‚Üí you get an automatic _multi-material_ label. | Only on **MatSynth** samples in Phases A, B, C (with the percentages we listed). |

So: crop_size = 256 px means ‚Äúmodel sees a 1024√ó1024 image whose content originated from a random 256-pixel window.‚Äù

**Why the curriculum crop schedule exists**

-   Small crops first (256 px) ‚Äì forces SegFormer and UNets to learn fine local patterns (wood grain, stone pores).
-   Larger crops later (512‚Üí768 px) ‚Äì introduce bigger structures (rivets, seams) once the lower-level filters are in place.
-   Full image in Phase D (2 K) ‚Äì no resizing at all, so you optimize true high-frequency detail.

### Phase-by-Phase cheat sheet

| Phase  | `crop_size`           | Composite mosaics?        | What the network finally receives                                                                                                                       |
| ------ | --------------------- | ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **A0** | **256 px**            | **OFF**                   | 1024¬≤ image made from one 256 px crop up-scaled to 1 K.                                                                                                 |
| **A**  | 256 px                | 2-crop 30 % / 4-crop 15 % | ‚Ä¢ Single-crop images (same as A0).<br>‚Ä¢ **30 % of batches**: two 256 px crops side-by-side ‚Üí still 1024¬≤.<br>‚Ä¢ **15 %**: four 256 px crops in 2√ó2 grid. |
| **B**  | 256 ‚Üí 512 px (linear) | Same composite rates as A | Early epochs: small crops; late epochs: larger crops. Composites constructed from whichever crop size is current.                                       |
| **C**  | 512 ‚Üí 768 px          | Composites at 20 % / 10 % | Even bigger context + sparser mosaics.                                                                                                                  |
| **C‚Ä≤** | full 1 K              | OFF                       | Pure resizing disabled; each texture scaled to exactly 1024¬≤ without cropping.                                                                          |
| **D**  | full 2 K              | OFF                       | Native 2048¬≤ textures, no cropping, no mosaics.                                                                                                         |

## Texture augmentation table

| Category                       | **Safe for ALL domains**<br>(apply blindly) | **Category-Selective**<br>(only if label is known or confidence > 0.8) | **Exclude / Never**                |
| ------------------------------ | ------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------- |
| **wood**                       | flips, 90¬∞ rot                              | ¬±10 % brightness, ¬±5 % hue, small grain-noise mask                     | heavy tint (green, purple)         |
| **stone**                      | flips, 90¬∞ rot                              | ¬±8 % brightness, Perlin dirt overlay                                   | hue shift (changes mineral colour) |
| **metal**                      | flips, 90¬∞ rot                              | subtle specular highlight sprite (white blotch Œ±=0.15)                 | hue shift (turns iron blue)        |
| **fabric / fur**               | flips, 90¬∞ rot                              | ¬±12 % hue/ sat, small warp (elastic-grid)                              | specular sprite                    |
| **leather**                    | flips, 90¬∞ rot                              | ¬±8 % hue, ¬±12 % brightness                                             | specular sprite                    |
| **ground / ceramic / plaster** | flips, 90¬∞ rot                              | ¬±10 % brightness, Perlin dirt                                          | hue shift > 5 %                    |
| **misc (dropped)**             | ‚Äî                                           | ‚Äî                                                                      | ‚Äî                                  |

_Composites are built after augmentation_

### How to integrate

```python
def safe_aug(img):
    # always on
    if random.random() < 0.5: img = TF.hflip(img)
    if random.random() < 0.5: img = TF.vflip(img)
    k = random.randint(0,3); img = img.rotate(90*k)
    return img

def selective_aug(img, cls_name):
    # MatSynth or confidently-labeled Skyrim
    if cls_name in ["wood","fabric","leather"]:
        img = TF.adjust_hue(img, random.uniform(-0.05,0.05))
    if cls_name in ["wood","stone","ground","ceramic"]:
        img = TF.adjust_brightness(img, random.uniform(0.9,1.1))
    if cls_name in ["fabric","fur"] and random.random()<0.3:
        img = elastic_warp(img)            # small cloth stretch
    if cls_name=="metal" and random.random()<0.3:
        img = overlay_highlight(img)
    return img

# MatSynth (labels are known)
img = safe_aug(img)
img = selective_aug(img, cls_name_from_folder)

# Skyrim (labels unknown)
# Before Phase B - apply only safe_aug
# Phase B onward - run SegFormer on the crop first

logits = segformer(img_small)          # (C,H,W)
conf, cls = logits.softmax(0).max(0)
if conf.mean() > 0.8:                  # high-confidence crop
    img = selective_aug(img, CLASSES[cls])
else:
    img = safe_aug(img)

```

---

## LPIPS

| Usage style                                          | Pros                                                                        | Cons                                                           | Recommended spot                                                                          |
| ---------------------------------------------------- | --------------------------------------------------------------------------- | -------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |
| **Validation‚Äëonly metric**                           | ‚Ä¢ Zero extra back‚Äëprop cost.<br>‚Ä¢ Simpler to code.                          | ‚Ä¢ Model optimises purely for L1/L2 ‚Üí can look overly smooth.   | **All phases** (always log `lpips_val`).                                                  |
| **Small‚Äëweight training term** (e.g. `0.05‚ÄØ√ó‚ÄØLPIPS`) | ‚Ä¢ Encourages sharper, perceptually pleasing results (important for albedo). | Adds one extra VGG forward pass per mini‚Äëbatch (‚âà8‚ÄØms on 1‚ÄØK). | **Phase‚ÄØA‚ÄëAlb‚ÄëSyn only** ‚Äî that‚Äôs where you fight baked lighting and ‚Äúidentity shortcut.‚Äù |
